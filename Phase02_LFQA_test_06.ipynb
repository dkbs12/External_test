{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkbs12/External_test/blob/main/Phase02_LFQA_test_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W4mAfAasA8L"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "pip install --upgrade pip\n",
        "pip install farm-haystack[colab,elasticsearch,inference,ocr,preprocessing,file-conversion,pdf]\n",
        "pip install datasets>=2.6.1\n",
        "\n",
        "apt install libgraphviz-dev\n",
        "pip install pygraphviz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "chown -R daemon:daemon elasticsearch-7.9.2"
      ],
      "metadata": {
        "id": "R28ndX89Sbng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -u daemon -- elasticsearch-7.9.2/bin/elasticsearch"
      ],
      "metadata": {
        "id": "suqT3LiMSbkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "from haystack.document_stores.elasticsearch import ElasticsearchDocumentStore\n",
        "\n",
        "time.sleep(30)\n",
        "\n",
        "host = os.environ.get(\"ELASTICSEARCH_HOST\", \"localhost\")\n",
        "\n",
        "document_store = ElasticsearchDocumentStore(host=host, username=\"\", password=\"\", index=\"document\", embedding_dim=1536)"
      ],
      "metadata": {
        "id": "7Ip2lrOd45kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.utils import fetch_archive_from_http, convert_files_to_docs\n",
        "from haystack.nodes import PreProcessor\n",
        "\n",
        "doc_dir = \"data/Phase1_test_data_04\"\n",
        "url = \"https://github.com/dkbs12/External_test/raw/main/Phase1_test_data_04.zip\"\n",
        "fetch_archive_from_http(url=url, output_dir=doc_dir)\n",
        "\n",
        "# convert files to dicts containing documents that can be indexed to our datastore\n",
        "got_docs = convert_files_to_docs(dir_path=doc_dir)"
      ],
      "metadata": {
        "id": "pT8s93ZRJSMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = PreProcessor(\n",
        "    clean_whitespace=True,\n",
        "    clean_header_footer=True,\n",
        "    clean_empty_lines=True,\n",
        "    split_by=\"word\",\n",
        "    split_length=200,\n",
        "    split_overlap=20,\n",
        "    split_respect_sentence_boundary=True,\n",
        ")\n",
        "\n",
        "all_docs = preprocessor.process(got_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc66473-bb65-4604-d8eb-89329324db6d",
        "id": "PLy-JblR8hMf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Preprocessing: 100%|██████████| 6/6 [00:00<00:00, 19.92docs/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_store.delete_documents()\n",
        "document_store.write_documents(all_docs)"
      ],
      "metadata": {
        "id": "7L18GrtN_q0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJFkt1LVsA8N",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6835d288-fd8a-4470-8dbf-216a0bb06f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating embeddings:   0%|          | 0/148 [00:00<?, ? Docs/s]\n",
            "Calculating embeddings:   0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "Calculating embeddings:   5%|▌         | 1/19 [00:00<00:17,  1.03it/s]\u001b[A\n",
            "Calculating embeddings:  11%|█         | 2/19 [00:01<00:15,  1.07it/s]\u001b[A\n",
            "Calculating embeddings:  16%|█▌        | 3/19 [00:03<00:19,  1.24s/it]\u001b[A\n",
            "Calculating embeddings:  21%|██        | 4/19 [00:04<00:16,  1.08s/it]\u001b[A\n",
            "Calculating embeddings:  26%|██▋       | 5/19 [00:05<00:13,  1.03it/s]\u001b[A\n",
            "Calculating embeddings:  32%|███▏      | 6/19 [00:05<00:11,  1.11it/s]\u001b[A\n",
            "Calculating embeddings:  37%|███▋      | 7/19 [00:06<00:10,  1.17it/s]\u001b[A\n",
            "Calculating embeddings:  42%|████▏     | 8/19 [00:07<00:09,  1.18it/s]\u001b[A\n",
            "Calculating embeddings:  47%|████▋     | 9/19 [00:08<00:09,  1.02it/s]\u001b[A\n",
            "Calculating embeddings:  53%|█████▎    | 10/19 [00:09<00:08,  1.02it/s]\u001b[A\n",
            "Calculating embeddings:  58%|█████▊    | 11/19 [00:10<00:07,  1.06it/s]\u001b[A\n",
            "Calculating embeddings:  63%|██████▎   | 12/19 [00:11<00:06,  1.07it/s]\u001b[A\n",
            "Calculating embeddings:  68%|██████▊   | 13/19 [00:12<00:05,  1.10it/s]\u001b[A\n",
            "Calculating embeddings:  74%|███████▎  | 14/19 [00:13<00:04,  1.11it/s]\u001b[A\n",
            "Calculating embeddings:  79%|███████▉  | 15/19 [00:14<00:03,  1.14it/s]\u001b[A\n",
            "Calculating embeddings:  84%|████████▍ | 16/19 [00:14<00:02,  1.18it/s]\u001b[A\n",
            "Calculating embeddings:  89%|████████▉ | 17/19 [00:15<00:01,  1.17it/s]\u001b[A\n",
            "Calculating embeddings:  95%|█████████▍| 18/19 [00:17<00:01,  1.01s/it]\u001b[A\n",
            "Calculating embeddings: 100%|██████████| 19/19 [00:17<00:00,  1.07it/s]\n",
            "Updating embeddings: 10000 Docs [00:20, 481.27 Docs/s]\n"
          ]
        }
      ],
      "source": [
        "from haystack.nodes import BM25Retriever, EmbeddingRetriever\n",
        "from haystack.utils import print_answers\n",
        "\n",
        "bm25_retriever = BM25Retriever(document_store=document_store)\n",
        "\n",
        "embedding_retriever = EmbeddingRetriever(\n",
        "    document_store=document_store, batch_size=8,\n",
        "    embedding_model=\"text-embedding-ada-002\", api_key=api_key, max_seq_len=1536\n",
        ")\n",
        "\n",
        "document_store.update_embeddings(embedding_retriever, update_existing_embeddings=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import PromptNode, PromptTemplate, AnswerParser\n",
        "\n",
        "prompt_template = PromptTemplate(prompt=\"Create a concise and informative answer (no more than 50 words) for a given question \"\n",
        "            \"based solely on the given documents. You must only use information from the given documents. \"\n",
        "            \"Use an unbiased and journalistic tone. Do not repeat text. Cite the documents using Document[number] notation. \"\n",
        "            \"If multiple documents contain the answer, cite those documents like ‘as stated in Document[number], Document[number], etc.’. \"\n",
        "            \"If the documents do not contain the answer to the question, say that ‘answering is not possible given the available information.’\\n\"\n",
        "            \"{join(documents, delimiter=new_line, pattern=new_line+'Document[$idx]: $content', str_replace={new_line: ' ', '[': '(', ']': ')'})} \\n Question: {query}; Answer: \",\n",
        "            output_parser=AnswerParser(reference_pattern=r\"Document\\[(\\d+)\\]\"),\n",
        "        )\n",
        "\n",
        "prompt_node = PromptNode(\n",
        "    model_name_or_path=\"text-davinci-003\", api_key=api_key, default_prompt_template=prompt_template,\n",
        "    use_gpu=True, max_length=200, top_k=1, model_kwargs={\"temperature\":0},\n",
        ")"
      ],
      "metadata": {
        "id": "i6JYnD5eJ3hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.pipelines import Pipeline\n",
        "from haystack.nodes import JoinDocuments\n",
        "\n",
        "# Create ensembled pipeline\n",
        "p_ensemble = Pipeline()\n",
        "p_ensemble.add_node(component=bm25_retriever, name=\"BM25Retriever\", inputs=[\"Query\"])\n",
        "p_ensemble.add_node(component=embedding_retriever, name=\"EmbeddingRetriever\", inputs=[\"Query\"])\n",
        "p_ensemble.add_node(\n",
        "    component=JoinDocuments(join_mode=\"concatenate\"), name=\"JoinResults\", inputs=[\"BM25Retriever\", \"EmbeddingRetriever\"]\n",
        ")\n",
        "p_ensemble.add_node(component=prompt_node, name=\"prompt_node\", inputs=[\"JoinResults\"])\n",
        "\n",
        "# Uncomment the following to generate the pipeline image\n",
        "# p_ensemble.draw(\"pipeline_ensemble.png\")"
      ],
      "metadata": {
        "id": "sxNytduE91aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = p_ensemble.run(\n",
        "    query=\"NDC는 무엇인가요??\", params={\"EmbeddingRetriever\": {\"top_k\": 2}, \"BM25Retriever\": {\"top_k\": 2}}\n",
        ")\n",
        "print_answers(res, details=\"minimum\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKvgPhD9qYcK",
        "outputId": "879de5fe-0266-4ea8-c2fb-be37a445a023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
            "WARNING:haystack.nodes.prompt.invocation_layer.open_ai:The prompt has been truncated from 4770 tokens to 3897 tokens so that the prompt length and answer length (200 tokens) fit within the max token limit (4097 tokens). Reduce the length of the prompt to prevent it from being cut off.\n",
            "WARNING:haystack.utils.openai_utils:1 out of the 1 completions have been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Query: NDC는 무엇인가요??'\n",
            "'Answers:'\n",
            "[   {   'answer': 'NDC는 XML 프로토콜을 기반으로 하는 데이터 교환 방식이며, API 중심 접근 방식을 규정하는 '\n",
            "                  '규칙이며, 항공 여행에만 적용되며, 직접 유통 비용 절감과 관련이 없습니다. As stated in '\n",
            "                  'Document[2],'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = p_ensemble.run(\n",
        "    query=\"항공사는 GDS를 통해 continuous pricing을 할 수 있는지 한국어로 답변 해 주세요.\", params={\"EmbeddingRetriever\": {\"top_k\": 2}, \"BM25Retriever\": {\"top_k\": 2}}\n",
        ")\n",
        "print_answers(res, details=\"minimum\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq7GEcRErVV4",
        "outputId": "28fab8f0-4d65-434b-e8a7-e2cb5d20face"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "WARNING:haystack.nodes.prompt.invocation_layer.open_ai:The prompt has been truncated from 6285 tokens to 3897 tokens so that the prompt length and answer length (200 tokens) fit within the max token limit (4097 tokens). Reduce the length of the prompt to prevent it from being cut off.\n",
            "WARNING:haystack.utils.openai_utils:1 out of the 1 completions have been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Query: 항공사는 GDS를 통해 continuous pricing을 할 수 있는지 한국어로 답변 해 주세요.'\n",
            "'Answers:'\n",
            "[   {   'answer': 'NDC는 항공사가 리셀러에게 맞춤형 제안, 유연한 실시간 티켓 가격, 레거시 시스템 종속성 감소 등을 '\n",
            "                  '제공하는 데 도움이 됩니다. 또한, 항공사는 GDS 채널에서 일부 요금 판매'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = p_ensemble.run(\n",
        "    query=\"Lufthansa Consulting의 수석 컨설턴트인 Esther Samtlebe는 뭐라고 말했는가??\", params={\"EmbeddingRetriever\": {\"top_k\": 2}, \"BM25Retriever\": {\"top_k\": 2}}\n",
        ")\n",
        "print_answers(res, details=\"medium\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P8XpGtkOCx2",
        "outputId": "9ad51383-b83c-4d54-98d6-0a483980d786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
            "WARNING:haystack.nodes.prompt.invocation_layer.open_ai:The prompt has been truncated from 6503 tokens to 3897 tokens so that the prompt length and answer length (200 tokens) fit within the max token limit (4097 tokens). Reduce the length of the prompt to prevent it from being cut off.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Query: Lufthansa Consulting의 수석 컨설턴트인 Esther Samtlebe는 뭐라고 말했는가??'\n",
            "'Answers:'\n",
            "[   {   'answer': 'What is the main purpose of NDC?\\n'\n",
            "                  '\\n'\n",
            "                  'As stated in Document[1] and Document[3], the main purpose '\n",
            "                  'of NDC is to enable airlines to customize and offer '\n",
            "                  'products through indirect channels, such as their website, '\n",
            "                  'in the same way they already do.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = p_ensemble.run(\n",
        "    query=\"NDC에 대한 오해는 무엇인가? 한국어로 답하시오.\", params={\"EmbeddingRetriever\": {\"top_k\": 2}, \"BM25Retriever\": {\"top_k\": 2}}\n",
        ")\n",
        "print_answers(res, details=\"minimum\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NOKdkCVwP85",
        "outputId": "8319964b-4b2f-479b-e405-93f557dd7e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n",
            "WARNING:haystack.nodes.prompt.invocation_layer.open_ai:The prompt has been truncated from 6280 tokens to 3897 tokens so that the prompt length and answer length (200 tokens) fit within the max token limit (4097 tokens). Reduce the length of the prompt to prevent it from being cut off.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Query: NDC에 대한 오해는 무엇인가? 한국어로 답하시오.'\n",
            "'Answers:'\n",
            "[   {   'answer': 'NDC는 XML 프로토콜을 기반으로 하는 데이터 교환 방식입니다. 또한, NDC는 API 중심 접근 방식을 '\n",
            "                  '규정하며 항공 여행에만 적용됩니다. As stated in Document[1], Document[3].'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ma8yih4mQ6FZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}